import json
import torch
from transformers import RobertaForSequenceClassification, RobertaTokenizer
from datasets import load_from_disk

# âœ… í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ
model_path = "./codebert_cwe_multi_label"
model = RobertaForSequenceClassification.from_pretrained(model_path)
tokenizer = RobertaTokenizer.from_pretrained("microsoft/codebert-base")

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# âœ… `test_dataset_new` ë¡œë“œ
test_dataset = load_from_disk("test_dataset")

# âœ… ë¼ë²¨ ì—­ë§¤í•‘ ë¡œë“œ
with open("label_map.json", "r", encoding="utf-8") as f:
    reverse_label_map = json.load(f)  # {0: 78, 1: 134, 2: 190, ...}

# âœ… CWE ì„ê³„ê°’ ì„¤ì •
THRESHOLD = 0.3

# âœ… ì „ì²´ ë°ì´í„°ì…‹ ì˜ˆì¸¡
results = []

for i in range(len(test_dataset)):
    sample_text = test_dataset[i]["code_snippet"]

    # âœ… ëª¨ë¸ ì…ë ¥ ë³€í™˜
    inputs = tokenizer(sample_text, return_tensors="pt", padding=True, truncation=True, max_length=512).to(device)

    # âœ… ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰
    model.eval()
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        probs = torch.sigmoid(logits)  # ë‹¤ì¤‘ ë ˆì´ë¸”ì´ë¯€ë¡œ Softmax ëŒ€ì‹  Sigmoid ì‚¬ìš©

    # âœ… CWE ID ë³€í™˜ (ì„ê³„ê°’ 0.3 ì´ìƒì¸ CWEë§Œ ì„ íƒ)
    predicted_labels = (probs > THRESHOLD).nonzero(as_tuple=True)[1].cpu().numpy()

    # âœ… ì˜ˆì¸¡ëœ ì¸ë±ìŠ¤ë¥¼ ì›ë˜ CWE IDë¡œ ë³€í™˜
    if len(predicted_labels) == 0:
        predicted_cwes = ["Safe Code"]  # CWEê°€ ì—†ìœ¼ë©´ ì•ˆì „í•œ ì½”ë“œë¡œ íŒë‹¨
    else:
        predicted_cwes = [reverse_label_map[str(idx)] for idx in predicted_labels]

    # # âœ… ëª¨ë“  CWE í™•ë¥  ì¶œë ¥ (ìƒìœ„ 3ê°œ)
    # prob_values = probs.cpu().numpy()[0]  # í™•ë¥  ê°’ ê°€ì ¸ì˜¤ê¸°
    # sorted_indices = prob_values.argsort()[::-1]  # í™•ë¥ ì´ ë†’ì€ ìˆœì„œëŒ€ë¡œ ì •ë ¬
    # top_cwes = [(reverse_label_map[str(idx)], prob_values[idx]) for idx in sorted_indices[:3]]
    
    # âœ… ëª¨ë“  CWE í™•ë¥  ì¶œë ¥ (ìƒìœ„ 3ê°œ) - float ë³€í™˜ ì¶”ê°€
    prob_values = probs.cpu().numpy()[0]  # í™•ë¥  ê°’ ê°€ì ¸ì˜¤ê¸°
    sorted_indices = prob_values.argsort()[::-1]  # í™•ë¥ ì´ ë†’ì€ ìˆœì„œëŒ€ë¡œ ì •ë ¬
    top_cwes = [(reverse_label_map[str(idx)], float(prob_values[idx])) for idx in sorted_indices[:3]]  # âœ… float ë³€í™˜ ì¶”ê°€


    # âœ… ì‹¤ì œ CWE ë¼ë²¨ í™•ì¸
    actual_cwe = test_dataset[i]["label"]

    # âœ… ê²°ê³¼ ì €ì¥
    results.append({
        "sample_index": i,
        "actual_cwe": actual_cwe,
        "predicted_cwes": predicted_cwes,
        "top_cwes": top_cwes
    })

    # ğŸ”¹ ì§„í–‰ ìƒí™© ì¶œë ¥ (100ê°œë§ˆë‹¤ ì¶œë ¥)
    if (i + 1) % 100 == 0:
        print(f"ğŸ”„ {i + 1}/{len(test_dataset)}ê°œ ì˜ˆì¸¡ ì™„ë£Œ...")

# âœ… JSON íŒŒì¼ë¡œ ì €ì¥
output_path = "test_predictions.json"
with open(output_path, "w", encoding="utf-8") as f:
    json.dump(results, f, indent=4)

print(f"\nâœ… ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ì™„ë£Œ!")
print(f"ğŸ“Š ê²°ê³¼ ì €ì¥: {output_path}")
