import torch
from transformers import RobertaForSequenceClassification, RobertaTokenizer
import json

# âœ… í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ
model_path = "./codebert_cwe_multi_label"
model = RobertaForSequenceClassification.from_pretrained(model_path)
tokenizer = RobertaTokenizer.from_pretrained("microsoft/codebert-base")

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# âœ… ë¼ë²¨ ì—­ë§¤í•‘ ë¡œë“œ
with open("label_map.json", "r", encoding="utf-8") as f:
    reverse_label_map = json.load(f)  # {0: 78, 1: 134, 2: 190, ...}

# âœ… ì·¨ì•½í•œ C ì½”ë“œ ì…ë ¥
bad_code = """
#include <stdio.h>
#include <stdlib.h>

void CWE127_Buffer_Underread__malloc_wchar_t_loop_14_bad()
{
    wchar_t * data;
    data = NULL;
    if(globalFive==5)
    {
        {
            wchar_t * dataBuffer = (wchar_t *)malloc(100*sizeof(wchar_t));
            if (dataBuffer == NULL) {exit(-1);}
            wmemset(dataBuffer, L'A', 100-1);
            dataBuffer[100-1] = L'\0';
            /* FLAW: Set data pointer to before the allocated memory buffer */
            data = dataBuffer - 8;
        }
    }
    {
        size_t i;
        wchar_t dest[100];
        wmemset(dest, L'C', 100-1); /* fill with 'C's */
        dest[100-1] = L'\0'; /* null terminate */
        /* POTENTIAL FLAW: Possibly copy from a memory location located before the source buffer */
        for (i = 0; i < 100; i++)
        {
            dest[i] = data[i];
        }
        /* Ensure null termination */
        dest[100-1] = L'\0';
        printWLine(dest);
        /* INCIDENTAL CWE-401: Memory Leak - data may not point to location
         * returned by malloc() so can't safely call free() on it */
    }
}

"""

# âœ… ëª¨ë¸ ì…ë ¥ ë³€í™˜
inputs = tokenizer(bad_code, return_tensors="pt", padding=True, truncation=True, max_length=512).to(device)

# âœ… ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰
model.eval()
with torch.no_grad():
    outputs = model(**inputs)
    logits = outputs.logits
    probs = torch.sigmoid(logits)  # ë‹¤ì¤‘ ë ˆì´ë¸”ì´ë¯€ë¡œ Softmax ëŒ€ì‹  Sigmoid ì‚¬ìš©

# âœ… CWE ID ë³€í™˜ (ì„ê³„ê°’ 0.3 ì´ìƒì¸ CWEë§Œ ì„ íƒ)
THRESHOLD = 0.3
predicted_labels = (probs > THRESHOLD).nonzero(as_tuple=True)[1].cpu().numpy()

# âœ… ì˜ˆì¸¡ëœ ì¸ë±ìŠ¤ë¥¼ ì›ë˜ CWE IDë¡œ ë³€í™˜
if len(predicted_labels) == 0:
    predicted_cwes = ["Safe Code"]  # CWEê°€ ì—†ìœ¼ë©´ ì•ˆì „í•œ ì½”ë“œë¡œ íŒë‹¨
else:
    predicted_cwes = [reverse_label_map[str(idx)] for idx in predicted_labels]

# âœ… ëª¨ë“  CWE í™•ë¥  ì¶œë ¥ (ìƒìœ„ 3ê°œ)
prob_values = probs.cpu().numpy()[0]  # í™•ë¥  ê°’ ê°€ì ¸ì˜¤ê¸°
sorted_indices = prob_values.argsort()[::-1]  # í™•ë¥ ì´ ë†’ì€ ìˆœì„œëŒ€ë¡œ ì •ë ¬
top_cwes = [(reverse_label_map[str(idx)], float(prob_values[idx])) for idx in sorted_indices[:3]]

print(f"\nğŸš€ ì…ë ¥ëœ ì½”ë“œ ì˜ˆì¸¡ ê²°ê³¼:")
print(f"ğŸ“Œ ì˜ˆì¸¡ëœ CWE ID: {predicted_cwes}")
print(f"ğŸ“Š ìƒìœ„ CWE í™•ë¥ : {top_cwes}")
